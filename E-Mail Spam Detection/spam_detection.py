# -*- coding: utf-8 -*-
"""spam_detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qe1naGxw1_l8oAU8gZt1WTHzjjFv000r

Import Libraries
"""

import numpy as np
import pandas as pd
import nltk
from nltk.corpus import stopwords
import string

"""Load the Data"""

from google.colab import files
uploaded = files.upload()

# Read the CSV file
df = pd.read_csv('emails.csv')

# Print the first 5 rows of data
df.head(5)

"""Print the shape (Get the number of rows and columns)"""

df.shape

"""Get the Columns Names"""

df.columns

"""Check for duplicates and remove them"""

df.drop_duplicates(inplace=True)

"""Show the new shape(number of rows and columns)"""

df.shape

"""Show the number of missing ( NAN, NaN, na) data for each column"""

df.isnull().sum()

"""Download the stopwords Package"""

nltk.download('stopwords')

def process_text(text):
  #1 remove punctuation
  nopunc = [char for char in text if char not in string.punctuation]
  nopunc = ''.join(nopunc)
  
  #2 remove stopwords
  clean_words = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]
  
  #3 return a list of clean text words
  return clean_words

"""Show the tokenization ( a list of tokens also called lemmas )"""

df['text'].head().apply(process_text)

"""Example"""

message4 = 'hello world hello hello world play'
message5 = 'test test test test one hello'
print(message4)
print()

"""Convert the text to a matrix of token counts"""

from sklearn.feature_extraction.text import CountVectorizer
bow4 = CountVectorizer(analyzer=process_text).fit_transform([[message4], [message5]])
print(bow4)
print()

print(bow4.shape)

"""Convert a collection of text to a matrix of tokens"""

from sklearn.feature_extraction.text import CountVectorizer
messages_bow = CountVectorizer(analyzer=process_text).fit_transform(df['text'])

"""Split the data into 80% training and 20% testing"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(messages_bow, df['spam'], test_size=0.20, random_state = 0)

"""Get the Shape of messages_bow"""

messages_bow.shape

"""Create and train the Naive Bayes Classifier"""

from sklearn.naive_bayes import MultinomialNB
classifier = MultinomialNB().fit(X_train, y_train)

"""Print The Predictions"""

print(classifier.predict(X_train))

"""Print the actual values"""

print(y_train.values)

"""Evaluate the model on the training data set"""

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
pred = classifier.predict(X_train)
print(classification_report(y_train, pred))
print()
print('Confusion Matrix: \n', confusion_matrix(y_train, pred))
print()
print('Accuracy: ', accuracy_score(y_train, pred))

print(classifier.predict(X_test))
print(y_test.values)

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
pred = classifier.predict(X_test)
print(classification_report(y_test, pred))
print()
print('Confusion Matrix: \n', confusion_matrix(y_test, pred))
print()
print('Accuracy: ', accuracy_score(y_test, pred))